{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aecde21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import csgraph, csr_matrix\n",
    "import xml.etree.ElementTree as et\n",
    "\n",
    "import noctiluca as nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff4870e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadXML(file, root='.'):\n",
    "    try:\n",
    "        tree = et.parse(file);\n",
    "    except OSError:\n",
    "        print(f'Failed to read XML file {file}.')\n",
    "        raise\n",
    "    \n",
    "    data = nl.TaggedSet()\n",
    "    \n",
    "    tracks = tree.getroot()\n",
    "    assert tracks.tag == 'Tracks'\n",
    "    \n",
    "    for particle in tracks:\n",
    "        if not particle.tag == 'particle':\n",
    "            continue\n",
    "        \n",
    "        frame  = np.array( [  int(spot.attrib['t']) for spot in particle  ])\n",
    "        xy     = np.array([[float(spot.attrib[key]) for key  in ['x', 'y']]\n",
    "                           for spot in particle])\n",
    "        \n",
    "        t = frame - np.min(frame)\n",
    "        \n",
    "        trajdata = np.empty((np.max(t)+1, 2), dtype=float)\n",
    "        trajdata[t] = xy\n",
    "        \n",
    "        traj = nl.Trajectory(trajdata)\n",
    "        traj.meta['real frame'] = np.arange(np.min(frame), np.max(frame)+1)\n",
    "        \n",
    "        data.add(traj)\n",
    "    \n",
    "    # get tags\n",
    "    tags = set()\n",
    "    tags.add(f'file={str(file.relative_to(root))}')\n",
    "    \n",
    "    for search, m_name in [('_(rep\\d)/', 'rep'),\n",
    "                           ('(U2OS|mESC)', 'cell line'),\n",
    "                          ]:\n",
    "        m = re.search(search, str(file))\n",
    "        if m is None:\n",
    "            print(f\"Warning: could not identify which {m_name} the file '{str(file)}' belongs to\")\n",
    "        else:\n",
    "            tags.add(m[1])\n",
    "    \n",
    "    m = re.match('Tracks_([^_]*)_([^_]*)_([^_]*)_([^_]*)_([^_]*)_\\d+.xml', file.name)\n",
    "    if m is None:\n",
    "        raise RuntimeError(f\"Filename {file.name} did not match expected pattern\")\n",
    "    else:\n",
    "        date      = m[1]\n",
    "        cellline  = m[2]\n",
    "        condition = m[3]\n",
    "        framerate = m[4]\n",
    "        cell      = m[5]\n",
    "        \n",
    "        # Fix inconsistencies etc.\n",
    "        if cellline  == 'U20S'    : cellline  = 'U2OS'\n",
    "        if cellline  == 'mESCs'   : cellline  = 'mESC'\n",
    "        if condition == '1uM-TSA' : condition = '1μM-TSA'\n",
    "        \n",
    "        tags |= {f'date={date}', condition, framerate, cellline}\n",
    "    \n",
    "    data.addTags(tags)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2241682c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1398"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = Path('../../raw_data/SPT/H2B')\n",
    "files = list(datapath.rglob('*.xml'))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8379684e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ede62106c0264deaaa4508f32f404d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1398 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load all\n",
    "# Files double as cell identifiers\n",
    "data = nl.TaggedSet()\n",
    "for file in tqdm(files):\n",
    "    data |= loadXML(file, datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b594cb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['100ms',\n",
       " '150nM-TSA',\n",
       " '1μM-TSA',\n",
       " '2s',\n",
       " '500nM-TSA',\n",
       " 'DMSO',\n",
       " 'DRB',\n",
       " 'ICRF',\n",
       " 'U2OS',\n",
       " 'date=20241207',\n",
       " 'date=20241208',\n",
       " 'date=20241209',\n",
       " 'date=20241213',\n",
       " 'date=20250116',\n",
       " 'date=20250118',\n",
       " 'mESC',\n",
       " 'rep1',\n",
       " 'rep2',\n",
       " 'rep3']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(filter(lambda tag: not tag.startswith('file='), data.tagset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e0fa53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef9e82e8ad7430896fb2ff7d9507003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/103281 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Precompute MSDs\n",
    "with nl.Parallelize():\n",
    "    _ = nl.analysis.MSD(data, chunksize=1, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337534c",
   "metadata": {},
   "source": [
    "# Get (all) pairwise trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "719fb749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d5f45e994b43b38a16625513059d16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720398\n"
     ]
    }
   ],
   "source": [
    "def SD(xm, xn): # for MSD calculation\n",
    "    return np.sum((xm-xn)**2, axis=-1)\n",
    "\n",
    "def parfun(file_tag):\n",
    "    data.makeSelection(file_tag)\n",
    "    data_out = nl.TaggedSet()\n",
    "\n",
    "    for i, (traj0, tags) in enumerate(data(giveTags=True)):\n",
    "        rf0 = traj0.meta['real frame']\n",
    "        rf0 = rf0[~np.any(np.isnan(traj0[:]), axis=-1)]\n",
    "        for j in range(i+1, len(data)):\n",
    "            traj1 = data[j]\n",
    "            rf1 = traj1.meta['real frame']\n",
    "            rf1 = rf1[~np.any(np.isnan(traj1[:]), axis=-1)]\n",
    "\n",
    "            rf_min = min(rf0.min(), rf1.min())\n",
    "            rf_max = max(rf0.max(), rf1.max())\n",
    "            cnt = np.zeros(rf_max+1-rf_min, dtype=int)\n",
    "            cnt[rf0-rf_min] += 1\n",
    "            cnt[rf1-rf_min] += 2\n",
    "            \n",
    "            valid = np.nonzero(cnt == 3)[0]\n",
    "            if len(valid) < 20: # the original data is also cut to >= 20 valid frames\n",
    "                continue\n",
    "                \n",
    "            valid_rf = valid + rf_min\n",
    "                \n",
    "            traj_dat = np.empty((2, valid_rf[-1]+1-valid_rf[0], traj0.d), dtype=float)\n",
    "            traj_dat[:] = np.nan\n",
    "            traj_dat[0, valid_rf - valid_rf[0]] = traj0[valid_rf - rf0.min()]\n",
    "            traj_dat[1, valid_rf - valid_rf[0]] = traj1[valid_rf - rf1.min()]\n",
    "            \n",
    "            traj = nl.Trajectory(traj_dat)\n",
    "            traj.meta['real frame'] = np.arange(valid_rf[0], valid_rf[-1]+1)\n",
    "            traj.meta['original data index 0'] = i\n",
    "            traj.meta['original data index 1'] = j\n",
    "            \n",
    "            # Precompute MSDs\n",
    "            # Note the use of preproc=... to calculate the correct MSD for the two-locus trajectories\n",
    "            # This will allow us to naively use nl.analysis.MSD in the future\n",
    "            # Do this here (instead of later), because it works nicely with parallelization\n",
    "            _ = nl.analysis.p2.P2(traj, function=SD, writeto='MSD', preproc=lambda traj: traj.relative())\n",
    "            \n",
    "            data_out.add(traj, tags.copy())\n",
    "            \n",
    "    return data_out\n",
    "\n",
    "data.makeSelection()\n",
    "file_tags = {tag for tag in data.tagset() if tag.startswith('file=')}\n",
    "\n",
    "data2 = nl.TaggedSet()\n",
    "todo = file_tags\n",
    "with Pool() as mypool:\n",
    "    imap = mypool.imap_unordered(parfun, todo)\n",
    "    imap = tqdm(imap, total=len(todo))\n",
    "    for dat in imap:\n",
    "        data2 |= dat\n",
    "\n",
    "print(len(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784557d1",
   "metadata": {},
   "source": [
    "# Remove cycles from two locus data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "641c2ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0401136e452d439abf4789376122d89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acyclic <1μm : 5382 trajectories\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21fa6ede6e5645029ebe2af9ef063ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acyclic <3μm : 50238 trajectories\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f34d3170db4cd1ae2c58f46477b8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1397 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seps = [1, 3, 5] # μm\n",
    "for max_mean_separation in seps:\n",
    "    sep_tag = f'acyclic <{max_mean_separation}μm'\n",
    "    \n",
    "    for file_tag in tqdm(file_tags):\n",
    "        data2.makeSelection(file_tag)\n",
    "        # Restrict to loci that are close in space\n",
    "        data2.refineSelection(lambda traj, _ : np.mean(np.linalg.norm(traj.relative()[:], axis=-1)) <= max_mean_separation)\n",
    "        if len(data2) == 0:\n",
    "            continue\n",
    "\n",
    "        # Assemble overlap matrix\n",
    "        rows = np.array([traj.meta['original data index 0'] for traj in data2])\n",
    "        cols = np.array([traj.meta['original data index 1'] for traj in data2])\n",
    "        overlaps = np.array([traj.relative().F              for traj in data2])\n",
    "\n",
    "        # Get maximal spanning tree\n",
    "        # (as minimal spanning tree of the negative overlaps)\n",
    "        N = np.max(np.concatenate([rows, cols]))+1\n",
    "        G = csr_matrix((-overlaps, (rows, cols)), shape=(N, N))\n",
    "        H = csgraph.minimum_spanning_tree(G)\n",
    "\n",
    "        # This is a bit hacky, maybe should be made easier in noctiluca\n",
    "        for (_, tags), i, j in zip(data2(giveTags=True), rows, cols):\n",
    "            if H[i, j] < 0:\n",
    "                tags.add(sep_tag)\n",
    "    \n",
    "    data2.makeSelection(sep_tag)\n",
    "    print(f'{sep_tag} : {len(data2):8>d} trajectories')\n",
    "data2.makeSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110e74a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filename = '../../data/20250121_SPT_H2B.h5'\n",
    "\n",
    "data.makeSelection()\n",
    "nl.io.write.hdf5({\n",
    "    'data' : data,\n",
    "    'conditions' : ['DMSO', 'DRB', '150nM-TSA', '500nM-TSA', '1μM-TSA', 'ICRF'],\n",
    "    'cell lines' : ['U2OS', 'mESC'],\n",
    "    'exposure_seconds' : {'100ms' : 0.08671, '2s' : 0.08671},\n",
    "    'description' : \"\"\"\n",
    "H2B SPT data\n",
    "\n",
    "Tracking H2B in U2OS/mESC cells, to be supplemented with MINFLUX. Conditions are\n",
    "\n",
    "    DMSO   DMSO-only control\n",
    "    DRB    txn inhibition\n",
    "    TSA    hyperacetylation (150nM, 500nM, 1μM; last only for mESC)\n",
    "    ICRF   topo-II inhibition\n",
    "    \n",
    "Framerates are 100ms or 2s.\n",
    "\n",
    "For all conditions we have three biological replicates, tagged 'rep1/2/3'.\n",
    "\"\"\"[1:-1]}, out_filename)\n",
    "\n",
    "data2.makeSelection()\n",
    "nl.io.write.hdf5(data2, out_filename, '/data_twoLocus_all')\n",
    "nl.io.write.hdf5(nl.io.load.hdf5(out_filename, 'description') + r\"\"\"\n",
    "\n",
    "The group 'data_twoLocus_all' contains the full pairwise data set, i.e. all\n",
    "two-locus trajectories within a given movie. Note that this is *highly*\n",
    "redundant and is saved here mostly for completeness. For processing, use\n",
    "one of the acyclic data sets below.\n",
    "\"\"\"[1:], out_filename, 'description')\n",
    "\n",
    "sep_tags = {tag for tag in data2.tagset() if tag.startswith('acyclic')}\n",
    "for sep_tag in sep_tags:\n",
    "    sep = int(re.search('<(\\d)+μm', sep_tag)[1])\n",
    "    data2.makeSelection(sep_tag)\n",
    "    nl.io.write.hdf5_subTaggedSet(data2, out_filename,\n",
    "                                  f'/data_twoLocus_acyclic_{sep}um',\n",
    "                                  refTaggedSet='/data_twoLocus_all',\n",
    "                                 )\n",
    "nl.io.write.hdf5(nl.io.load.hdf5(out_filename, 'description') + r\"\"\"\n",
    "\n",
    "The groups 'data_twoLocus_acyclic_Xum' are subsets of the two-locus data; the idea\n",
    "is to make the neighbor graph acyclic, which exactly removes redundancy (e.g. with\n",
    "loci 1, 2, 3, only two of the three two-locus trajectories 1--2, 2--3, 3--1 are\n",
    "independent). Clearly we get some freedom of choice in which trajectories to kick\n",
    "out when removing cycles; so we can score trajectories by some metric and choose\n",
    "the best ones. We generally want to keep longer trajectories over shorter ones; in\n",
    "addition, we favor trajectories that are closer together (the whole idea of this\n",
    "two-locus data set is to remove large scale motion, so we want to be local). In\n",
    "the present case, we assembled three data sets, with distance cutoffs 1, 3, 5 μm\n",
    "as indicated in the group name. Choose whichever seems most useful/reasonable.\n",
    "\"\"\"[1:], out_filename, 'description')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
