{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "n_proc = 1 # define number of processes for multiprocessing\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "import noctiluca as nl\n",
    "from multiprocessing import Pool\n",
    "from itertools import product\n",
    "import pickle\n",
    "import warnings\n",
    "import minflux\n",
    "import trajectories\n",
    "import bayesmsd\n",
    "import pandas as pd\n",
    "\n",
    "# Settings the warnings to be ignored\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate MINFLUX on fBms\n",
    "### Define MINFLUX parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(minflux)\n",
    "minflux_l150 = minflux.Minflux2D()\n",
    "\n",
    "minflux_l150.beam_offsets_cartesian = minflux_l150.calc_evenly_spaced_points(6)\n",
    "minflux_l150.add_minflux_L(150)\n",
    "minflux_l150.beam_pattern = lambda r, z, center: minflux_l150.donut_beam(r, z, 360, 350, center)\n",
    "minflux_l150.define_multiplex_cycle(20.0, 5.0, 5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracking_params = {\"dt\": 1,\n",
    "                   \"background_emission_rate\": 0.015,\n",
    "                   \"minimum_photon_threshold\": 10,\n",
    "                   \"background_threshold\": 80000,\n",
    "                   \"maximum_dark_time\": 300000,\n",
    "                   \"stickiness\": 4,\n",
    "                   \"beta\": np.array([1, 1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate a few trajectories to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trajectories = 2\n",
    "alphas = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "output_trajectories = {a: [] for a in alphas}\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(alpha)\n",
    "    for i in tqdm.tqdm(range(n_trajectories)):\n",
    "        fbm_generator = trajectories.FractionalBrownianMotion(1, alpha / 2)\n",
    "        fbm = fbm_generator.computation_method(fbm_generator.covariance_sequence,\n",
    "                                               10000 * int(minflux_l150.multiplex_cycle_time),\n",
    "                                               (3,))\n",
    "        fbm *= np.sqrt(fbm_generator.calculate_variance(1))\n",
    "        fbm = np.cumsum(fbm, axis=0)\n",
    "        output_trajectories[alpha].append(fbm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine msds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbm_scaling = 4\n",
    "\n",
    "colors = ['orangered', 'orchid', 'orange', 'gray', 'royalblue',\n",
    "          'turquoise', 'limegreen', 'crimson', 'cyan']\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "for alpha in alphas:\n",
    "    artists = nl.plot.msd_overview(nl.make_TaggedSet(output_trajectories[alpha][0][:10000].T),\n",
    "                                   dt=1, label=f\"{alpha}\")\n",
    "    for a in artists[:-1]:\n",
    "        a.remove()\n",
    "    artists[-1].set_color(colors[i])\n",
    "\n",
    "x = np.logspace(0, 3)\n",
    "for a in alphas:\n",
    "    plt.plot(x, x**a)\n",
    "\n",
    "plt.ylim([1, 100])\n",
    "plt.xlabel(\"frame\")\n",
    "plt.ylabel(\"displacement\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate tracking on a bunch of trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parfun(curr_todo):\n",
    "    fbm, alpha, scale, L_val, per = curr_todo\n",
    "    key = (alpha, scale, L_val, per)\n",
    "    return key, minflux_l150._track_particle(scale * fbm, L_value=L_val, photon_emission_rate=per, **tracking_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trajectories = 150\n",
    "alphas = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "scales = np.sqrt(np.logspace(1, 2.6, 10))\n",
    "L_values = [25, 50, 100, 150, 200]\n",
    "pers = [0.5, 1, 2]\n",
    "\n",
    "output_path = \"\" # provide output path\n",
    "\n",
    "for alpha in alphas:\n",
    "    print(alpha)\n",
    "    tracking_outputs = {a: [] for a in product(alphas, scales, L_values, pers)}\n",
    "    error_outputs = {a: [] for a in product(alphas, scales, L_values, pers)}\n",
    "    photon_emission_rates_outputs = {a: [] for a in product(alphas, scales, L_values, pers)}\n",
    "\n",
    "    ground_truth_motion_blurred = {a: [] for a in alphas}\n",
    "    ground_truth_subsampled = {a: [] for a in alphas}\n",
    "\n",
    "    fbm_generator = trajectories.FractionalBrownianMotion(1, alpha / 2)\n",
    "    for i in tqdm.tqdm(range(n_trajectories)):\n",
    "        fbm = fbm_generator.computation_method(fbm_generator.covariance_sequence,\n",
    "                                               11000 * int(minflux_l150.multiplex_cycle_time),\n",
    "                                               (3,))\n",
    "        fbm *= np.sqrt(fbm_generator.calculate_variance(1))\n",
    "        fbm = np.cumsum(fbm, axis=0)\n",
    "        fbm -= fbm[0, :]\n",
    "        localization_chunks = np.split(\n",
    "                fbm,\n",
    "                fbm.shape[0] / int(minflux_l150.multiplex_cycle_time),\n",
    "                axis=0\n",
    "            )\n",
    "        ground_truth_motion_blurred[alpha].append(np.concatenate([np.mean(chunk, axis=0) for chunk in localization_chunks]))\n",
    "        ground_truth_subsampled[alpha].append(fbm[::int(minflux_l150.multiplex_cycle_time / tracking_params[\"dt\"]), :])\n",
    "        todo = product([fbm], [alpha], scales, L_values, pers)\n",
    "        with Pool(processes=n_proc) as mypool:\n",
    "            minflux_list = list(mypool.imap(parfun, todo))\n",
    "        for key, val in minflux_list:\n",
    "            tracking_outputs[key].append(val[0])\n",
    "            error_outputs[key].append(val[1])\n",
    "            photon_emission_rates_outputs[key].append(val[2])\n",
    "    with open(os.path.join(output_path, f'position_estimates_alpha_{alpha}.pickle'), 'wb') as handle:\n",
    "        pickle.dump(tracking_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(output_path, f'position_errors_alpha_{alpha}.pickle'), 'wb') as handle:\n",
    "        pickle.dump(error_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(output_path, f'emission_rates_alpha_{alpha}.pickle'), 'wb') as handle:\n",
    "        pickle.dump(photon_emission_rates_outputs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(output_path, f'ground_truth_motion_blurred_{alpha}.pickle'), 'wb') as handle:\n",
    "        pickle.dump(ground_truth_motion_blurred, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(os.path.join(output_path, f'ground_truth_subsampled_{alpha}.pickle'), 'wb') as handle:\n",
    "        pickle.dump(ground_truth_subsampled, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block may be used to read the simulation outputs. Otherwise, proceed to the following block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
    "\n",
    "position_estimates = []\n",
    "position_errors = []\n",
    "emission_rates = []\n",
    "gt_motion_blurred = []\n",
    "gt_subsampled = []\n",
    "\n",
    "\n",
    "for alpha in alphas:\n",
    "    with open(os.path.join(output_path, f'position_estimates_alpha_{alpha}.pickle'), 'rb') as handle:\n",
    "        position_estimates.append(pickle.load(handle))\n",
    "\n",
    "    with open(os.path.join(output_path, f'position_errors_alpha_{alpha}.pickle'), 'rb') as handle:\n",
    "        position_errors.append(pickle.load(handle))\n",
    "\n",
    "    with open(os.path.join(output_path, f'emission_rates_alpha_{alpha}.pickle'), 'rb') as handle:\n",
    "        emission_rates.append(pickle.load(handle))\n",
    "\n",
    "    with open(os.path.join(output_path, f'ground_truth_motion_blurred_{alpha}.pickle'), 'rb') as handle:\n",
    "        gt_motion_blurred.append(pickle.load(handle))\n",
    "\n",
    "    with open(os.path.join(output_path, f'ground_truth_subsampled_{alpha}.pickle'), 'rb') as handle:\n",
    "        gt_subsampled.append(pickle.load(handle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_position_estimates = {}\n",
    "all_position_errors = {}\n",
    "all_emission_rates = {}\n",
    "all_motion_blurred = {}\n",
    "all_subsampled = {}\n",
    "for pos_estimate, pos_error, emission_rate in zip(position_estimates, position_errors, emission_rates):\n",
    "    for key, val in pos_estimate.items():\n",
    "        if len(val) > 0:\n",
    "            all_position_estimates[key] = val\n",
    "            all_position_errors[key] = pos_error[key]\n",
    "            all_emission_rates[key] = emission_rate[key]\n",
    "for motion_blurred, subsampled in zip(gt_motion_blurred, gt_subsampled):\n",
    "    for key, val in motion_blurred.items():\n",
    "        if len(val) > 0:\n",
    "            all_motion_blurred[key] = val\n",
    "            all_subsampled[key] = subsampled[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make noctiluca sets\n",
    "minflux_set = nl.TaggedSet()\n",
    "key_labels = [\"alpha=\", \"scale=\", \"L=\", \"per=\"]\n",
    "for key, position_estimate in all_position_estimates.items():\n",
    "    tagset = [a + f\"{v:.2f}\" for a, v in zip(key_labels, key)]\n",
    "    for curr_position_estimate in position_estimate:\n",
    "        minflux_set.add(nl.Trajectory(curr_position_estimate.T), tags=tagset)\n",
    "\n",
    "gt_set = nl.TaggedSet()\n",
    "for key, subsampled in all_subsampled.items():\n",
    "    for curr_subsampled in subsampled:\n",
    "        gt_set.add(nl.Trajectory(curr_subsampled[:, :2]), tags=[f\"alpha={key:.2f}\",\n",
    "                                                                \"blurred=False\"])\n",
    "    for curr_motion_blurred in all_motion_blurred[key]:\n",
    "        gt_set.add(nl.Trajectory(curr_motion_blurred.reshape(curr_subsampled.shape)[:, :2]),\n",
    "                   tags=[f\"alpha={key:.2f}\", \"blurred=True\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSDs for ground truth dataset\n",
    "gt_set.makeSelection()\n",
    "_ = nl.analysis.MSD(tqdm.tqdm(gt_set))\n",
    "nl.io.write.hdf5(gt_set, os.path.join(output_path, \"ground_truth_data.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate MSDs for MINFLUX dataset\n",
    "def parfun(args):\n",
    "    i, traj = args\n",
    "    _ = nl.analysis.MSD(traj)\n",
    "    return i, traj.meta['MSD']\n",
    "\n",
    "todo = list(enumerate(minflux_set))\n",
    "with Pool(processes=n_proc) as mypool:\n",
    "    imap = mypool.imap_unordered(parfun, todo)\n",
    "    imap = tqdm.tqdm(imap, total=len(todo))\n",
    "    for i, msd_meta in imap:\n",
    "        minflux_set[i].meta['MSD'] = msd_meta\n",
    "nl.io.write.hdf5(minflux_set, os.path.join(output_path, \"simulated_minflux_data.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze simulated trajectories\n",
    "Read outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"\"\n",
    "\n",
    "gt_set = nl.io.load.hdf5(os.path.join(output_path, \"ground_truth_data.h5\"))\n",
    "minflux_set = nl.io.load.hdf5(os.path.join(output_path, \"simulated_minflux_data.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine available tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minflux_set.tagset())\n",
    "print(gt_set.tagset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_msd(t, cycles, dt, scale, alpha):\n",
    "    \"\"\"A function for the MSD of the fBm without motion blur or localization\n",
    "    error.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t :\n",
    "        Time lag\n",
    "    cycles :\n",
    "        The MINFLUX cycles\n",
    "    dt :\n",
    "        The timestep of the MINFLUX simulation\n",
    "    scale : float\n",
    "        The scaling factor for the fBm\n",
    "    alpha : float\n",
    "        The alpha for the fBm\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A function for the MSD without localization error or motion blur\n",
    "    \"\"\"\n",
    "    return 2 * scale**2 * cycles**alpha * (t / dt) ** alpha\n",
    "\n",
    "def params2msd(cycles, dt, scale, alpha, sigma2, motion_blur):\n",
    "    \"\"\"Makes an MSD with motion blur and localization error from the given\n",
    "    parameters\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cycles :\n",
    "        The MINFLUX cycles\n",
    "    dt : float\n",
    "        The timestep of the MINFLUX simulation\n",
    "    scale : float\n",
    "        The scaling factor for the fBm\n",
    "    alpha : float\n",
    "        The alpha for the fBm\n",
    "    sigma2 : float\n",
    "        Localization error\n",
    "    motion_blur : float\n",
    "        Motion blur to apply\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        An function for the MSD with motion blur and localization error\n",
    "    \"\"\"\n",
    "\n",
    "    @bayesmsd.deco.MSDfun\n",
    "    @bayesmsd.deco.imaging(noise2=sigma2,\n",
    "                           f=motion_blur,\n",
    "                           alpha0=alpha,\n",
    "                          )\n",
    "    def mb_msd(t, cycles=cycles, dt=dt, scale=scale, alpha=alpha):\n",
    "        return default_msd(t, cycles, dt, scale, alpha)\n",
    "    return mb_msd\n",
    "\n",
    "def msd_plot_only_ensemble(data, color=\"black\", nl_kwargs={}):\n",
    "    \"\"\"Helper function to plot only the ensemble average of MSD.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data :\n",
    "        The data to be plotted\n",
    "    color : str, optional\n",
    "        The color of the ensemble line, by default \"black\"\n",
    "    nl_kwargs : dict, optional\n",
    "        kwargs to pass to noctiluca, by default {}\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "       Artists objects from matplotlib.\n",
    "    \"\"\"\n",
    "    artists = nl.plot.msd_overview(data, **nl_kwargs)\n",
    "    for a in artists[:-1]:\n",
    "        a.remove()\n",
    "    artists[-1].set_color(color)\n",
    "    return artists\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce motion blur SI figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 5, figsize=(12, 9))\n",
    "for j, scale in enumerate([5.84, 8.80, 13.25]):\n",
    "    for i, alpha in enumerate([0.1, 0.15, 0.2, 0.25, 0.3]):\n",
    "        minflux_set.makeSelection()\n",
    "        L_vals = [25, 50, 100, 150, 200]\n",
    "        dt = 2.1e-4\n",
    "        per=0.5\n",
    "        for L in L_vals:\n",
    "            if L == 25:\n",
    "                per = 2.0\n",
    "            elif L == 50:\n",
    "                per = 2.0\n",
    "            else:\n",
    "                per = 1.0\n",
    "            minflux_set.makeSelection(tags=[f\"alpha={alpha:.2f}\",\n",
    "                                            f\"scale={scale:.2f}\",\n",
    "                                            f\"L={L:.2f}\",\n",
    "                                            f\"per={per:.2f}\"],\n",
    "                                            logic=all)\n",
    "            e_msd = nl.analysis.MSD(minflux_set)\n",
    "            x_vals = dt * np.arange(1, e_msd.shape[0])\n",
    "            ax[j, i].loglog(x_vals, e_msd[1:], label=f\"Minflux L={L}\")\n",
    "\n",
    "        gt_set.makeSelection(tags=[f\"alpha={alpha:.2f}\", \"blurred=False\"],\n",
    "                             logic=all)\n",
    "        e_msd = nl.analysis.MSD(gt_set)\n",
    "        x_vals = dt * np.arange(1, e_msd.shape[0])\n",
    "        ax[j, i].loglog(x_vals, scale**2 * e_msd[1:], \"r\",\n",
    "                        label=\"raw subsampled\")\n",
    "\n",
    "        gt_set.makeSelection(tags=[f\"alpha={alpha:.2f}\", \"blurred=True\"],\n",
    "                             logic=all)\n",
    "        e_msd = nl.analysis.MSD(gt_set)\n",
    "        x_vals = dt * np.arange(1, e_msd.shape[0])\n",
    "        ax[j, i].loglog(x_vals, scale**2 * e_msd[1:], \"r\", label=\"motion blurred\")\n",
    "\n",
    "        x_vals = np.logspace(np.log10(x_vals[0]), np.log10(x_vals[-1]))\n",
    "        ax[j, i].plot(x_vals, default_msd(x_vals, 1, 180, dt, scale, alpha),\n",
    "                      \"k\", label=\"theoretical\")\n",
    "        motion_blur_msd = params2msd(1, 180, dt, scale, alpha, 0, dt)\n",
    "        ax[j, i].plot(x_vals, motion_blur_msd(x_vals), \"k--\",\n",
    "                      label=\"theoretical+motion blur\")\n",
    "        ax[j, i].set_xlim([x_vals[0], x_vals[-1]])\n",
    "        ax[j, i].set_title(\n",
    "            f\"alpha={alpha:.2f}, scale={scale:.2f}, per={per:.2f}\"\n",
    "            )\n",
    "        ax[j, i].set_xlabel(\"time (s)\")\n",
    "        ax[j, i].set_ylabel(\"displacement (nm^2)\")\n",
    "        ax[j, i].set_aspect(1./ax[j, i].get_data_ratio())\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"motion_blur_sim_multiple_alpha_multiple_scale.svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frap_spt_simulation",
   "language": "python",
   "name": "frap_spt_simulation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
